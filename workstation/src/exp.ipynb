{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /media/gaston/gaston1/pro/envs/actia/lib/python3.10/site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2934,  0.7496,  0.0298,  0.6885,  0.2576,  0.4183,  0.6098,\n",
      "            0.5581,  0.4596,  0.6959,  0.7601,  0.6012,  0.1844,  0.6143,\n",
      "            0.3729,  0.3686],\n",
      "          [ 0.2226,  0.2489,  0.7342, -0.0440,  0.5824,  0.3492,  0.7194,\n",
      "            0.0847,  0.3853,  0.9299, -0.0835,  0.7122,  0.4734,  0.4886,\n",
      "            0.0520,  0.5180],\n",
      "          [ 0.3903,  0.9785,  0.2720,  0.3218,  0.4021,  0.5943,  0.2930,\n",
      "            0.8108, -0.0618,  0.5473,  0.7174,  0.3333,  0.2123,  1.3025,\n",
      "            0.6022,  0.4878],\n",
      "          [ 0.4036,  0.3093,  0.2662,  0.4898,  0.1147,  0.3808,  0.9981,\n",
      "            0.1506,  1.2372,  1.1260,  0.4228,  0.0624,  0.9751,  0.1683,\n",
      "            0.4065,  0.7740],\n",
      "          [ 0.2886,  0.2034, -0.1459,  0.4930,  0.8807, -0.5096,  0.0829,\n",
      "            0.3380,  0.3801,  0.9325,  0.6704,  0.5806,  0.0240,  0.2116,\n",
      "           -0.0629,  0.5145],\n",
      "          [ 0.4846,  0.4377,  0.7570,  0.3116,  0.6457,  0.0429,  0.8268,\n",
      "           -0.2849,  0.6896,  0.4779, -0.0809,  0.7978,  0.7566, -0.2763,\n",
      "            0.3916,  0.4335],\n",
      "          [ 0.3525,  0.8360,  0.0544,  0.3364,  0.3786,  0.3690,  0.3020,\n",
      "            0.1550,  1.1466, -0.7902,  0.9445,  0.2704,  0.0926,  0.6097,\n",
      "            0.4500,  0.2933],\n",
      "          [ 0.1574,  0.5225,  0.6862,  0.3248,  0.2620,  0.0289,  0.5635,\n",
      "            0.4344,  0.4898,  0.6492,  0.6414,  0.1171,  0.4226,  0.4256,\n",
      "            0.3723,  0.7041],\n",
      "          [ 0.7626,  0.7325, -0.3191,  0.5463,  0.2160,  0.0194,  0.4063,\n",
      "            0.2847,  0.4707,  1.2466, -0.8000,  0.2345,  0.6104,  0.0147,\n",
      "            0.4630,  0.1861],\n",
      "          [ 0.2934,  0.5917,  0.3654,  0.7655, -0.1931,  0.4776,  0.3277,\n",
      "            0.5081,  0.1181,  0.6891,  0.7214,  0.4776,  0.7109,  0.1756,\n",
      "            0.9337,  0.7548],\n",
      "          [ 0.7376,  0.2528,  0.4975, -0.5004,  0.3153,  1.5129,  1.2693,\n",
      "           -0.1440,  0.2083,  0.7422, -0.4458,  0.1044,  0.5653,  0.3346,\n",
      "            0.2811,  1.3079],\n",
      "          [ 1.2491,  0.0616,  0.3509,  0.7861,  0.3278,  0.0042,  0.7056,\n",
      "            1.0371,  0.0623,  0.3029,  0.8214,  0.3948,  0.3638,  0.3335,\n",
      "            0.2682,  0.7451],\n",
      "          [ 0.4604,  0.8564,  0.4396,  0.3277,  0.7244,  0.6455,  0.9707,\n",
      "            0.4916,  0.8405,  0.7740, -0.1265,  0.3015,  0.6264,  0.0502,\n",
      "            0.3819,  0.3491],\n",
      "          [ 0.2018,  0.5449,  0.6605,  0.5241,  0.2679,  0.1237,  0.6436,\n",
      "            0.6947,  0.2454,  1.1845,  0.4515,  0.1265,  0.7530,  0.5672,\n",
      "            0.4530,  0.3945],\n",
      "          [ 0.8934,  0.6608, -0.0713,  0.7994,  0.5139,  0.3424,  0.4875,\n",
      "            0.6676, -0.1281,  0.4813, -0.2074, -0.1458,  0.8855,  0.2667,\n",
      "            0.3940,  0.7671],\n",
      "          [ 0.1309,  0.7077, -0.0568,  0.3079,  0.3625,  0.1739,  0.4651,\n",
      "            0.3151,  0.1653,  0.5070,  0.4473,  0.4209,  0.1394,  0.3689,\n",
      "            0.3307,  0.4546]],\n",
      "\n",
      "         [[ 0.0107, -0.3830, -0.2455, -0.1330, -0.2016,  0.0195, -0.2697,\n",
      "           -0.2580, -0.0259, -0.4621, -0.1368, -0.3816,  0.1461, -0.2849,\n",
      "           -0.1369, -0.2145],\n",
      "          [ 0.0604, -0.1231,  0.1266,  0.0481, -0.3589, -0.2331, -0.3733,\n",
      "           -0.1426, -0.0423, -0.2981,  0.1461,  0.1171, -0.1150, -0.4978,\n",
      "            0.0466, -0.1129],\n",
      "          [ 0.0908, -0.5147, -0.1842, -0.1148, -0.7369, -0.2263, -0.0023,\n",
      "           -0.3419,  0.0334, -0.1599, -0.0685, -0.1075, -0.1659, -0.3337,\n",
      "           -0.4794, -0.1082],\n",
      "          [-0.0292, -0.2149, -0.3621, -0.4852, -0.3613, -0.0867, -0.8989,\n",
      "           -0.0963, -0.3308, -0.3704, -0.1147, -0.0451, -0.7272, -0.3048,\n",
      "           -0.3626, -0.4371],\n",
      "          [-0.0160,  0.0195, -0.3807,  0.0173, -0.8643,  0.0913, -0.3769,\n",
      "           -0.0091, -0.0055, -0.0743, -0.2273, -0.2935, -0.4612, -0.1018,\n",
      "           -0.3252, -0.1943],\n",
      "          [ 0.1670, -0.1069, -0.2273, -0.1322, -1.0739, -0.0889, -0.3505,\n",
      "           -0.0330, -0.2895, -0.2178, -0.0958, -0.0915, -0.3528,  0.0740,\n",
      "           -0.0346, -0.0646],\n",
      "          [ 0.0359, -0.2643, -0.1884, -0.1239, -0.2008, -0.0680, -0.3384,\n",
      "           -0.3169, -0.6040,  0.2528, -0.1637, -0.0776, -0.3930, -0.0987,\n",
      "           -0.3007, -0.0518],\n",
      "          [ 0.0407, -0.0277, -0.3666, -0.4410, -0.2627,  0.0951, -0.2815,\n",
      "           -0.3765, -0.1511, -0.3936, -0.2809, -0.0042, -0.4554,  0.0121,\n",
      "           -0.1620, -0.2311],\n",
      "          [-0.0388, -0.6395, -0.0531, -0.1528, -0.2200, -0.0992, -0.3050,\n",
      "           -0.1331,  0.0208, -0.8639, -0.0302, -0.0315, -0.2473,  0.1265,\n",
      "           -0.1477, -0.0183],\n",
      "          [-0.0476,  0.0990, -0.0441, -0.3344,  0.0899, -0.1876, -0.3219,\n",
      "           -0.1472, -0.1459, -0.1622, -0.0804, -0.0385, -0.2242,  0.0953,\n",
      "           -0.1177, -0.2866],\n",
      "          [-0.3768, -0.0374, -0.1779,  0.1525, -0.1371, -0.0784, -0.5828,\n",
      "           -0.3143,  0.1010, -0.3924, -0.1543, -0.0850, -0.5012, -0.0315,\n",
      "            0.0729, -0.4178],\n",
      "          [-0.1465,  0.0593,  0.0178, -0.0115, -0.0942,  0.0551, -0.2504,\n",
      "           -0.4302, -0.0846, -0.3710, -0.2150,  0.0354, -0.2313, -0.1673,\n",
      "           -0.0714, -0.2573],\n",
      "          [ 0.0060, -0.5936, -0.0873, -0.0797, -0.2746,  0.0482, -0.4302,\n",
      "           -0.4892, -0.1309, -0.7474, -0.0211,  0.0129, -0.3905,  0.1120,\n",
      "           -0.1173, -0.0952],\n",
      "          [-0.2061, -0.1532, -0.0843, -0.5061, -0.0210, -0.2318, -0.3822,\n",
      "           -0.5059, -0.1933, -0.7368, -0.0925, -0.0959, -0.0754, -0.2432,\n",
      "           -0.1880, -0.2321],\n",
      "          [-0.4922, -0.2117,  0.0321, -0.2204, -0.0727, -0.1700,  0.0503,\n",
      "           -0.3576,  0.0407, -0.1959, -0.1528,  0.0316, -0.3311, -0.1019,\n",
      "           -0.0167, -0.3736],\n",
      "          [-0.1910, -0.3641, -0.0598, -0.0867,  0.0123, -0.1158, -0.2520,\n",
      "           -0.6446, -0.0042, -0.0618, -0.0630, -0.0137, -0.0274, -0.0189,\n",
      "           -0.0071, -0.1770]],\n",
      "\n",
      "         [[ 0.2107,  0.0639, -0.1455, -0.0067,  0.1685,  0.1571,  0.1445,\n",
      "           -0.0699,  0.3293, -0.2288, -0.0078, -0.1643,  0.4261,  0.0516,\n",
      "            0.1646, -0.0898],\n",
      "          [ 0.2263, -0.1528,  0.3395,  0.2369, -0.2401, -0.1476, -0.2093,\n",
      "           -0.0230, -0.1029, -0.2241, -0.3138, -0.0387,  0.4597, -0.5065,\n",
      "           -0.1007, -0.0400],\n",
      "          [ 0.1541, -0.0611,  0.5123, -0.0400, -0.8117, -0.2116, -0.0518,\n",
      "            0.1164,  0.1815, -0.2883, -0.0987,  0.0365, -0.2104, -0.3408,\n",
      "           -0.4714, -0.0057],\n",
      "          [ 0.0936, -0.1222,  0.0958, -0.2855, -0.4634,  0.0925, -0.5278,\n",
      "           -0.1758, -0.4491, -0.2783,  0.2772,  0.1504, -0.4281, -0.4337,\n",
      "           -0.2769, -0.2115],\n",
      "          [ 0.0200,  0.4280, -0.6830,  0.2698, -0.4054, -0.1093, -0.5207,\n",
      "            0.2960, -0.0658, -0.1470, -0.1052, -0.0521, -0.6609, -0.0379,\n",
      "           -0.6953,  0.0779],\n",
      "          [ 0.3256,  0.0701,  0.2954, -0.0309, -0.7881,  0.1075,  0.3581,\n",
      "           -0.1854, -0.1853, -0.0854, -0.0532, -0.0257,  0.5993,  0.0859,\n",
      "            0.1577,  0.6404],\n",
      "          [-0.0954, -0.0355, -0.1077,  0.0628,  0.1846,  0.2056, -0.3935,\n",
      "           -0.3755,  0.0110, -0.0430,  0.2220,  0.0517, -0.1945,  0.4111,\n",
      "           -0.1475,  0.1697],\n",
      "          [ 0.1901,  0.3220, -0.0045, -0.4208, -0.0983, -0.1076, -0.2688,\n",
      "           -0.4727, -0.1538, -0.2923, -0.1336,  0.1687, -0.4578, -0.0974,\n",
      "            0.0716, -0.0997],\n",
      "          [ 0.1150, -0.3425, -0.1323, -0.0500, -0.4086, -0.0469, -0.2090,\n",
      "            0.1133,  0.1965, -0.4861, -0.4501,  0.1175, -0.2008, -0.0249,\n",
      "            0.1587,  0.2203],\n",
      "          [-0.0429, -0.0091,  0.3280, -0.3037,  0.0164,  0.0212, -0.2066,\n",
      "            0.3251, -0.3258,  0.4252,  1.0745,  0.2462, -0.0486, -0.0254,\n",
      "           -0.1763, -0.2619],\n",
      "          [-0.0344,  0.1041,  0.0429,  0.2139, -0.0311, -0.0884, -0.2210,\n",
      "           -0.1632,  0.1147,  0.1353, -0.3578, -0.0427, -0.3081,  0.0530,\n",
      "           -0.0125,  0.0026],\n",
      "          [ 0.1281,  0.3820, -0.1470, -0.0479, -0.0483,  0.0569,  0.2389,\n",
      "            0.7587,  0.1347, -0.4536, -0.4971,  0.1480, -0.0854, -0.0546,\n",
      "           -0.0547, -0.1158],\n",
      "          [ 0.3630,  0.2333, -0.0279, -0.0085, -0.2361,  0.2617,  0.1849,\n",
      "           -0.2295,  0.2125, -0.5218, -0.1116, -0.0665, -0.3018,  0.4123,\n",
      "            0.0478,  0.1394],\n",
      "          [-0.0625, -0.0283, -0.1380, -0.6234, -0.0078,  0.0967, -0.1548,\n",
      "           -0.3978, -0.5322, -0.7398,  0.3212, -0.0982,  0.2045, -0.1180,\n",
      "           -0.0827,  0.0240],\n",
      "          [-0.2319, -0.2025, -0.0998,  0.2911, -0.0225, -0.2746,  0.3412,\n",
      "            0.1101,  0.0550,  0.1006,  0.0237, -0.0654, -0.1643,  0.0522,\n",
      "            0.1490, -0.1433],\n",
      "          [-0.1736, -0.0421,  0.0174,  0.0396,  0.6150, -0.2333,  0.0652,\n",
      "           -0.4357,  0.2915,  0.3437,  0.1383,  0.2248,  0.0059,  0.1808,\n",
      "            0.3197,  0.2338]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "device=\"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.bn1(self.conv1(inputs)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        return x, p\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2)\n",
    "        self.conv = conv_block(2 * out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class segUnet(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=3, depth=5, start_filts=64):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.start_filts = start_filts\n",
    "        self.depth = depth\n",
    "\n",
    "        \"\"\" Encoders \"\"\"\n",
    "        self.encoders = nn.ModuleList([encoder_block(in_channels, start_filts)])\n",
    "        self.encoders.extend([encoder_block(start_filts * (2 ** i), start_filts * (2 ** (i + 1))) for i in range(depth - 1)])\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.bottleneck = conv_block(start_filts * (2 ** (depth - 1)), start_filts * (2 ** depth))\n",
    "\n",
    "        \"\"\" Decoders \"\"\"\n",
    "        self.decoders = nn.ModuleList([decoder_block(start_filts * (2 ** i), start_filts * (2 ** (i - 1))) for i in range(depth, 0, -1)])\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(start_filts, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        skips = []\n",
    "        x = inputs\n",
    "        for encoder in self.encoders:\n",
    "            x, p = encoder(x)\n",
    "            skips.append(x)\n",
    "            x = p\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        for i, decoder in enumerate(self.decoders):\n",
    "            x = decoder(x, skips[-(i+1)])\n",
    "\n",
    "        outputs = self.outputs(x)\n",
    "        return outputs\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate the model and move it to the appropriate device\n",
    "model = segUnet(num_classes=3, in_channels=3, depth=3, start_filts=8).to(device)\n",
    "\n",
    "# Print model summary using torchinfo\n",
    "summary(model, input_size=(1, 3,16, 16), device=device)\n",
    "x=torch.randn((1,3,16,16))\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Res34Unet                                          [1, 3, 64, 64]            --\n",
       "├─Unet: 1-1                                        [1, 3, 64, 64]            --\n",
       "│    └─ResNetEncoder: 2-1                          [1, 3, 64, 64]            13,114,368\n",
       "│    │    └─Conv2d: 3-1                            [1, 64, 32, 32]           9,408\n",
       "│    │    └─BatchNorm2d: 3-2                       [1, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-3                              [1, 64, 32, 32]           --\n",
       "│    │    └─MaxPool2d: 3-4                         [1, 64, 16, 16]           --\n",
       "│    │    └─Sequential: 3-5                        [1, 64, 16, 16]           221,952\n",
       "│    │    └─Sequential: 3-6                        [1, 128, 8, 8]            1,116,416\n",
       "│    │    └─Sequential: 3-7                        [1, 256, 4, 4]            6,822,400\n",
       "│    └─UnetDecoder: 2-2                            [1, 64, 64, 64]           --\n",
       "│    │    └─Identity: 3-8                          [1, 256, 4, 4]            --\n",
       "│    │    └─ModuleList: 3-9                        --                        6,676,224\n",
       "│    └─SegmentationHead: 2-3                       [1, 3, 64, 64]            --\n",
       "│    │    └─Conv2d: 3-10                           [1, 3, 64, 64]            1,731\n",
       "│    │    └─Identity: 3-11                         [1, 3, 64, 64]            --\n",
       "│    │    └─Activation: 3-12                       [1, 3, 64, 64]            --\n",
       "====================================================================================================\n",
       "Total params: 27,962,627\n",
       "Trainable params: 27,962,627\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.99\n",
       "====================================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 20.48\n",
       "Params size (MB): 59.39\n",
       "Estimated Total Size (MB): 79.92\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "class Res34Unet(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=3,start_filts=64, depth=4, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.depth = depth\n",
    "        self.negative_slope=negative_slope\n",
    "        self.start_filts=start_filts \n",
    "        self.internal_masks=[]\n",
    "\n",
    "        decoder_channels=tuple([(2**i)*self.start_filts for i in range(self.depth,0,-1)])\n",
    "        self.model =  smp.Unet(\n",
    "            encoder_name=\"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=\"imagenet\",\n",
    "            decoder_use_batchnorm=True,\n",
    "            decoder_channels=decoder_channels,\n",
    "            encoder_depth=self.depth ,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=self.in_channels,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=num_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model6=Res34Unet(num_classes=3,in_channels=3,start_filts=4,depth=4)\n",
    "# Print model summary using torchinfo\n",
    "summary(model6, input_size=(1, 3,64,64), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.1729e-02, -8.2027e-01, -6.7957e-01, -1.1168e+00, -6.9178e-01,\n",
      "           -2.4227e-01, -6.0260e-01, -3.4603e-01, -2.2835e-01,  7.2157e-01,\n",
      "           -2.5448e-01, -7.2431e-01,  3.0075e-01, -1.3035e+00, -5.3631e-01,\n",
      "            5.6581e-01],\n",
      "          [ 4.9090e-01, -9.1410e-01, -7.4854e-01, -6.9451e-01, -4.7431e-01,\n",
      "           -1.0747e+00, -1.0025e+00, -1.9974e-01, -1.0810e+00, -5.8953e-01,\n",
      "           -1.6099e-01, -2.9569e-01,  1.2158e-01, -5.3102e-01, -6.1296e-01,\n",
      "            8.3656e-01],\n",
      "          [-6.0371e-02, -4.7486e-01, -8.1461e-02, -9.5704e-01, -6.0165e-01,\n",
      "           -3.5285e-01, -7.1410e-01, -1.1587e+00, -1.4112e+00, -1.6577e+00,\n",
      "           -1.0785e+00, -7.6726e-01,  2.3278e-01,  5.0061e-01, -3.2182e-01,\n",
      "            8.1539e-01],\n",
      "          [ 7.1781e-01, -7.5229e-01, -7.2120e-01, -3.1911e-01, -6.3669e-01,\n",
      "           -8.4784e-01, -1.4153e+00, -1.4862e+00, -2.0706e+00, -1.6637e+00,\n",
      "           -9.1859e-01, -6.5429e-01,  1.0354e-01,  1.3613e-01, -1.4652e-01,\n",
      "            8.5943e-01],\n",
      "          [-3.9063e-01, -8.1828e-01, -6.2073e-01, -6.3578e-01, -1.0461e+00,\n",
      "           -5.9692e-01, -9.1433e-01, -5.7553e-01, -1.1902e+00, -9.0329e-01,\n",
      "           -1.5348e+00, -1.2316e+00,  5.5892e-01,  8.9991e-01,  1.6838e-01,\n",
      "            7.6934e-01],\n",
      "          [-7.3430e-01, -1.2522e+00,  9.9091e-02, -6.3452e-01, -7.4654e-01,\n",
      "           -5.1449e-01,  1.5396e-01, -4.9249e-02, -3.2512e-01, -5.3882e-01,\n",
      "           -1.7804e+00, -1.4415e-01,  1.0270e+00,  4.3485e-01,  1.5666e-01,\n",
      "            4.9407e-01],\n",
      "          [ 2.9034e-01, -1.1381e+00,  2.3465e-02,  1.5843e-01, -7.8904e-02,\n",
      "           -3.3539e-01, -1.0246e-01, -7.5692e-01, -3.6546e-01, -2.4157e-01,\n",
      "           -1.1335e+00, -5.6317e-01,  1.0779e+00, -7.6103e-01, -2.0894e-01,\n",
      "           -3.9676e-01],\n",
      "          [ 9.1228e-01,  5.4925e-02, -9.9865e-01, -2.2795e-01,  8.7363e-02,\n",
      "           -8.4721e-01,  9.1790e-02, -1.0315e-01, -1.4680e+00, -1.8571e+00,\n",
      "           -7.1943e-01, -1.2967e+00, -1.5633e-01, -9.0447e-01, -7.4447e-01,\n",
      "           -2.5558e-01],\n",
      "          [ 7.1990e-01,  3.4338e-01,  8.6238e-01,  9.4043e-01, -3.8552e-01,\n",
      "           -3.8141e-02,  1.9403e-01,  1.0414e-01, -1.4174e+00, -9.7934e-02,\n",
      "           -1.3655e+00, -1.3076e+00, -1.3612e+00,  3.9923e-02,  4.3139e-02,\n",
      "           -5.8815e-01],\n",
      "          [-2.7844e-02, -2.1694e-01, -6.0269e-02,  3.6201e-01, -2.9948e-02,\n",
      "           -2.5754e-01, -7.4932e-01, -8.4459e-01, -1.9227e+00, -1.7734e+00,\n",
      "           -3.5196e-01, -9.6350e-01, -1.1223e+00, -8.5836e-01, -2.4429e-02,\n",
      "            4.3724e-01],\n",
      "          [-2.4787e-01, -4.5944e-01, -1.6109e-01,  3.0614e-01,  9.2506e-01,\n",
      "            7.0744e-01, -1.7463e-01, -7.7592e-01, -1.9570e+00, -2.3332e-01,\n",
      "            5.8495e-01, -5.1988e-02, -2.3156e-01, -6.7252e-01,  1.6096e-01,\n",
      "            6.4675e-01],\n",
      "          [-1.1350e+00, -1.0995e+00,  1.9237e-01,  8.0724e-01,  4.9017e-01,\n",
      "            1.3176e+00,  5.6980e-01,  2.8638e-02, -1.6010e+00, -6.0053e-01,\n",
      "            1.8363e-01, -6.6558e-01, -2.0673e-02, -9.7008e-02, -2.7083e-01,\n",
      "            3.6674e-01],\n",
      "          [-3.2528e-01, -5.0079e-01,  4.2511e-01, -5.4175e-01, -2.0548e-01,\n",
      "           -3.4420e-01,  9.0304e-01, -2.3892e-01, -1.1579e+00, -5.0899e-01,\n",
      "           -7.0833e-01, -1.6270e+00, -3.8252e-01, -5.8749e-01, -7.6210e-01,\n",
      "            2.3773e-03],\n",
      "          [-1.9563e-01, -2.0061e-01, -3.1271e-01, -1.4749e+00, -9.5132e-01,\n",
      "           -6.4663e-01,  8.4689e-02,  1.0360e-01, -8.0454e-01,  1.6003e-01,\n",
      "           -1.2392e+00, -1.0602e+00,  3.3065e-02, -1.1572e+00, -5.0333e-01,\n",
      "            3.2003e-02],\n",
      "          [-1.6529e-01, -1.6805e-01, -6.1325e-01, -1.7486e+00, -2.2759e+00,\n",
      "           -1.4405e+00, -5.7689e-01, -3.1748e-01, -1.4158e+00, -9.5386e-01,\n",
      "           -1.3009e+00, -1.2711e+00, -7.1615e-01, -1.9649e+00, -1.2175e+00,\n",
      "            3.9613e-01],\n",
      "          [-2.3574e-01,  1.3175e-01, -1.1159e-01, -9.5445e-01, -4.0031e-02,\n",
      "           -6.2015e-01, -3.2508e-01, -1.2426e-01, -4.2613e-01, -2.7290e-01,\n",
      "           -9.5330e-02, -8.4930e-01, -1.8037e-01, -1.6423e+00, -5.1647e-01,\n",
      "            8.3295e-01]],\n",
      "\n",
      "         [[ 1.6352e-01,  6.2386e-02,  1.0456e-01, -2.4335e-01, -6.1773e-01,\n",
      "           -3.8712e-01,  3.4395e-02, -4.0030e-01, -1.7755e-01, -3.6249e-01,\n",
      "            7.7097e-02,  5.1201e-01, -1.1202e-01, -6.7343e-01, -4.5062e-01,\n",
      "           -9.5039e-03],\n",
      "          [ 6.1403e-01, -1.3297e-02, -6.1383e-01, -4.6463e-01, -2.7719e-01,\n",
      "           -4.1330e-01, -4.3994e-01, -6.5370e-01, -4.8221e-01, -2.8883e-02,\n",
      "           -6.5124e-01, -1.2183e-01, -1.1152e+00, -1.1413e+00, -1.0486e+00,\n",
      "            1.1551e-01],\n",
      "          [-5.0261e-01, -1.0844e+00, -9.0094e-01, -1.0022e+00, -8.2779e-01,\n",
      "           -1.3515e+00, -1.1843e+00, -1.0156e+00, -1.4835e+00, -1.3229e-01,\n",
      "           -1.3035e+00, -1.1082e+00, -1.5025e+00, -2.0320e+00, -1.3246e+00,\n",
      "           -6.7823e-01],\n",
      "          [ 1.1793e+00,  3.6649e-02, -1.1228e+00, -6.8991e-01, -4.4868e-01,\n",
      "           -6.0604e-01, -6.4826e-01, -1.5248e-01, -1.8293e+00, -1.0682e+00,\n",
      "           -1.4536e+00, -1.5140e+00, -1.5360e+00, -1.6504e+00, -1.1448e+00,\n",
      "           -5.4538e-01],\n",
      "          [ 4.7898e-01, -1.3100e+00, -1.7699e+00, -2.0498e+00, -5.5059e-01,\n",
      "           -1.3085e-01, -7.0121e-02, -4.9250e-01, -1.3314e+00, -1.6046e+00,\n",
      "           -1.1337e+00, -1.2389e+00, -1.4823e+00, -5.6068e-01, -7.3787e-01,\n",
      "           -1.1434e-02],\n",
      "          [-6.6966e-02, -1.4009e+00, -1.6318e+00, -2.1166e+00, -5.3953e-01,\n",
      "            1.5125e-01, -3.8128e-01, -1.5954e+00, -1.1561e+00, -1.4603e+00,\n",
      "           -1.6274e+00, -1.5042e+00, -2.2997e+00, -6.9733e-01, -7.6891e-01,\n",
      "           -4.8460e-01],\n",
      "          [ 4.9309e-01,  1.5593e-01, -2.2775e-01, -3.3764e-01,  7.0880e-01,\n",
      "           -3.0923e-01, -2.0498e+00, -2.5848e+00, -8.1883e-01, -8.2407e-01,\n",
      "           -1.0656e+00, -1.6025e+00, -2.1084e+00, -1.0506e+00, -9.5559e-01,\n",
      "           -5.8427e-01],\n",
      "          [ 1.1125e+00, -6.9165e-01, -7.6105e-01, -6.1869e-01, -1.1475e-01,\n",
      "           -6.5348e-01, -5.2369e-01, -1.7700e+00, -4.5803e-01, -2.0429e-01,\n",
      "           -5.0620e-02, -9.7399e-01, -7.0987e-01, -3.2972e-01, -6.3890e-01,\n",
      "           -3.6137e-01],\n",
      "          [ 8.6355e-01, -7.7956e-01, -2.2652e-01,  2.2390e-01, -5.5918e-01,\n",
      "            1.5920e-01,  1.4365e-01, -1.1191e+00, -8.1685e-01, -2.7108e-01,\n",
      "           -8.9836e-01, -1.2838e+00, -1.2007e+00, -1.5563e-01, -5.0402e-01,\n",
      "           -8.2500e-01],\n",
      "          [ 1.4580e+00,  3.3992e-01,  8.1684e-01,  2.1221e-01, -1.1555e-01,\n",
      "           -2.0112e-01,  8.8866e-01,  1.0115e-01, -9.0636e-01, -1.6497e+00,\n",
      "           -1.8398e+00, -1.3256e+00, -8.6689e-01, -9.2417e-01, -5.5259e-01,\n",
      "           -5.6013e-01],\n",
      "          [ 1.6439e+00, -5.8253e-01, -2.7835e-01, -7.5318e-01, -5.4109e-01,\n",
      "           -1.0531e+00,  3.7684e-01, -5.1809e-01, -8.9567e-01,  8.6142e-02,\n",
      "           -1.7408e-01, -2.5480e-02, -4.8583e-01, -1.0734e+00, -2.1545e-01,\n",
      "            3.4825e-01],\n",
      "          [ 1.0863e+00, -1.7796e-01, -4.3036e-01,  2.5546e-01,  1.1684e-01,\n",
      "           -7.8178e-01, -1.0396e+00, -4.4646e-01, -1.3911e+00,  9.0501e-03,\n",
      "            1.5744e-01,  3.8603e-01,  3.0026e-01,  1.4012e-01, -8.3899e-01,\n",
      "           -1.6520e-01],\n",
      "          [ 3.4333e-01,  2.6023e-01, -2.4569e-01, -1.9881e-01, -2.7658e-01,\n",
      "           -1.2517e-01,  4.8895e-01,  1.0270e+00, -4.8612e-01, -4.8451e-01,\n",
      "            1.5024e-01, -1.0106e+00, -3.1562e-01,  3.0962e-01, -2.5539e-01,\n",
      "           -5.2980e-01],\n",
      "          [ 3.9864e-01, -2.4734e-01,  5.0228e-03, -6.8603e-01, -7.9448e-01,\n",
      "           -1.9406e-01, -5.2334e-02,  4.6225e-01,  2.7574e-01, -4.0969e-01,\n",
      "            1.7765e-01, -1.1431e+00, -1.5479e+00, -6.6081e-01, -8.2269e-01,\n",
      "           -1.4238e+00],\n",
      "          [ 5.8202e-02, -7.4316e-01,  2.4912e-02, -3.0455e-01, -4.3738e-01,\n",
      "           -8.3825e-01, -1.2698e+00, -6.7494e-01,  2.7385e-01, -5.6209e-01,\n",
      "           -6.2827e-01,  1.8674e-01, -4.7678e-01, -2.4400e-01, -7.8451e-01,\n",
      "           -1.2897e+00],\n",
      "          [ 5.5665e-01,  4.0621e-01, -6.5287e-02, -1.1738e+00, -1.1227e+00,\n",
      "           -9.9685e-01, -7.7814e-01, -1.1089e+00, -9.3071e-01, -8.0624e-01,\n",
      "           -1.1287e+00, -5.0916e-01, -5.6936e-01, -1.7712e+00, -1.3767e+00,\n",
      "           -1.1333e+00]],\n",
      "\n",
      "         [[-6.3663e-02,  2.2484e-01, -3.6892e-01, -3.9740e-01,  8.7003e-02,\n",
      "            3.1098e-02,  4.9650e-02, -1.4710e-01, -2.1529e-01,  1.9885e-01,\n",
      "           -1.0273e-01, -4.7973e-01, -5.5720e-01, -6.8272e-01, -3.7958e-01,\n",
      "           -1.8196e-02],\n",
      "          [-6.4781e-01, -1.1392e+00, -3.3298e-01,  1.4545e-01,  3.4435e-01,\n",
      "            1.0942e+00, -3.1738e-01, -6.6975e-01, -1.1290e-01, -1.0221e-01,\n",
      "           -5.5838e-01, -1.0199e+00, -1.2342e+00, -1.1851e+00, -2.0363e-01,\n",
      "           -5.0494e-01],\n",
      "          [-6.4861e-01,  3.4421e-02, -1.3827e+00, -5.7106e-01, -7.6473e-02,\n",
      "            6.0902e-01, -8.7432e-01, -3.7972e-01, -1.0127e-01, -6.1116e-01,\n",
      "           -3.2943e-01, -9.5200e-01, -8.3422e-01, -1.4814e+00, -3.6315e-01,\n",
      "           -7.6818e-01],\n",
      "          [-9.0224e-01, -1.3671e+00, -1.0908e+00, -5.2536e-02, -3.3319e-01,\n",
      "           -1.1201e-01, -4.9163e-01, -1.9627e-01, -4.7370e-01, -1.5482e-01,\n",
      "           -1.0516e+00, -7.0272e-01, -8.7151e-01, -1.8114e+00, -6.4878e-01,\n",
      "           -1.3895e-01],\n",
      "          [-1.5165e+00, -1.9526e+00, -6.7517e-01,  2.6899e-01,  2.2751e-01,\n",
      "           -7.5755e-01,  8.6575e-01,  1.6529e+00,  1.9717e-01, -2.3894e-01,\n",
      "           -1.1232e+00, -8.9178e-01, -6.4801e-01, -8.5106e-01, -1.5082e-01,\n",
      "           -3.9658e-01],\n",
      "          [-1.7661e+00, -1.4925e+00, -5.8617e-01, -1.0742e+00, -4.9600e-01,\n",
      "           -1.6048e-01, -9.7119e-01, -9.9323e-01, -1.2378e+00, -1.4342e+00,\n",
      "           -1.1028e+00, -6.3026e-01, -6.2205e-01, -8.2430e-01,  1.1604e-01,\n",
      "            2.2441e-01],\n",
      "          [-5.9522e-01, -1.2182e+00,  7.5835e-02, -9.7363e-01, -1.4032e+00,\n",
      "           -1.4972e-01, -1.7196e+00, -2.3096e+00, -2.0777e-01, -1.2327e+00,\n",
      "           -1.3734e+00,  9.8384e-01,  3.3495e-01, -5.7559e-01,  7.7741e-01,\n",
      "            1.9124e-01],\n",
      "          [-1.5309e-01, -1.5853e+00, -7.3227e-02,  1.9667e-01, -1.8631e+00,\n",
      "           -8.9501e-01, -2.2003e+00, -1.7584e+00, -6.5634e-02, -1.7590e+00,\n",
      "           -1.5386e+00, -1.6497e-01, -7.4141e-01,  1.6345e-01, -2.8745e-02,\n",
      "           -4.0885e-02],\n",
      "          [-1.1091e+00, -9.9872e-01, -5.6418e-01, -1.2629e+00,  5.0946e-01,\n",
      "           -1.3497e+00, -1.7554e+00, -1.6194e+00,  5.1164e-02, -7.0293e-01,\n",
      "           -1.2201e+00, -7.3725e-01, -1.2920e+00, -1.0761e+00, -7.7786e-01,\n",
      "           -8.5921e-01],\n",
      "          [-1.3139e+00, -1.5933e+00, -9.3193e-01, -7.8284e-01,  4.7682e-01,\n",
      "            1.0786e+00, -9.4077e-01, -1.5676e+00,  2.5478e-01, -5.2205e-01,\n",
      "           -8.6626e-01, -4.9845e-01, -1.4996e+00, -4.3147e-01, -8.4604e-01,\n",
      "           -3.1750e-01],\n",
      "          [-1.5347e+00, -2.0631e+00, -1.1805e+00, -8.1076e-01, -2.5482e-01,\n",
      "            5.9786e-02,  5.6083e-01, -7.5061e-01,  6.3441e-01,  6.5058e-01,\n",
      "            8.2446e-02, -5.0091e-01, -1.0137e+00,  8.6882e-01,  3.1294e-01,\n",
      "            1.0249e-01],\n",
      "          [-9.2543e-01, -1.4920e+00, -1.9918e+00, -1.3054e+00, -8.2756e-01,\n",
      "           -3.2543e-01,  6.8483e-01,  1.0336e+00,  1.1325e+00,  1.3687e+00,\n",
      "           -5.5368e-01,  2.8206e-01, -1.3994e+00, -6.8646e-02,  9.8094e-01,\n",
      "            1.2399e-01],\n",
      "          [-2.8639e-01, -6.0301e-01, -2.8263e-01,  6.5094e-01,  8.5359e-02,\n",
      "            5.2099e-01, -2.2690e-01, -1.1288e+00,  6.8714e-02,  1.0784e+00,\n",
      "            5.2966e-01,  4.9245e-01,  3.3994e-01, -3.9099e-01,  1.1137e-01,\n",
      "           -1.7635e-01],\n",
      "          [-1.1527e-01, -8.5870e-02, -9.7009e-01, -1.2871e-01, -2.6555e-01,\n",
      "           -3.2924e-01,  6.8983e-02, -3.3806e-01, -6.4126e-01, -1.8865e-01,\n",
      "            2.4309e-01,  1.0213e-01,  5.3999e-01, -9.7388e-02, -5.2328e-01,\n",
      "            3.4948e-01],\n",
      "          [ 1.7041e-01,  8.9391e-01, -5.6388e-01, -1.3389e+00, -1.2966e+00,\n",
      "            1.1116e-01,  6.2243e-01, -3.8684e-01,  1.9177e-01,  4.0546e-01,\n",
      "            5.1993e-01,  7.5222e-01,  7.6947e-01, -6.5162e-01, -1.0304e+00,\n",
      "           -6.0434e-03],\n",
      "          [-1.6035e-01, -2.2103e-01, -8.7948e-01, -1.6656e-01,  8.7911e-01,\n",
      "            7.2908e-01,  5.7651e-01, -3.8520e-01, -1.4877e-01,  1.9879e-01,\n",
      "            7.7581e-01,  1.2822e+00,  1.4064e+00,  8.6754e-01,  7.7773e-01,\n",
      "            3.6189e-01]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=torch.inf)\n",
    "\n",
    "x=torch.randn((1,3,16,16))\n",
    "print(model6(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
