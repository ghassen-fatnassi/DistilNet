# Autonomous Driving Segmentation Task ğŸš—ğŸ¨

This project focuses on segmentation tasks for autonomous driving using the Cityscapes dataset. It supports distributed training and mixed precision and includes a logging mechanism with WandB to log important metrics.

## Folder Structure ğŸ“‚

```
workstation
â”œâ”€â”€ ğŸ“ data
â”‚   â””â”€â”€ ğŸ“ cityscapes
â”‚       â”œâ”€â”€ ğŸ“ images ğŸ–¼ï¸ (contains the dataset images)
â”‚       â””â”€â”€ ğŸ“ masks ğŸ­ (contains the dataset masks)
â”œâ”€â”€ ğŸ“ logs ğŸ“
â”‚   â””â”€â”€ ğŸ“ wandb ğŸ“Š (contains the WandB logs)
â”œâ”€â”€ ğŸ“ models ğŸ¤–
â”‚   â”œâ”€â”€ ğŸ“ Students ğŸ‘©â€ğŸ“ (contains the student models in pth format)
â”‚   â””â”€â”€ ğŸ“ Teachers ğŸ‘¨â€ğŸ« (contains the teacher models in pth format)
â”œâ”€â”€ ğŸ“ src ğŸ“¦
â”‚   â”œâ”€â”€ ğŸ“ config ğŸ› ï¸
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ config.yaml ğŸ“ (contains the project configuration)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ SegFormer.yaml ğŸ“ (contains the SegFormer model configuration)
â”‚   â”‚   â””â”€â”€ ğŸ“„ UNet.yaml ğŸ“ (contains the UNet model configuration)
â”‚   â”œâ”€â”€ ğŸ“ models ğŸ¤–
â”‚   â”‚   â””â”€â”€ ğŸ“„ UNet.py ğŸ“ (contains the UNet model implementation)
â”‚   â””â”€â”€ ğŸ“ training ğŸ‹ï¸â€â™‚ï¸
â”‚       â”œâ”€â”€ ğŸ“„ train.py ğŸ“ (contains the training script)
â”‚       â”œâ”€â”€ ğŸ“„ engine.py ğŸ“ (contains the training engine)
â”‚       â”œâ”€â”€ ğŸ“„ dataset.py ğŸ“ (contains the dataset class)
â”‚       â”œâ”€â”€ ğŸ“„ loss.py ğŸ“ (contains the custom loss functions)
â”‚       â”œâ”€â”€ ğŸ“„ distill.py ğŸ“ (contains the distillation logic)
â”‚       â”œâ”€â”€ ğŸ“„ utils.py ğŸ“ (contains utility functions)
â”‚       â””â”€â”€ ğŸ“„ init.py ğŸ“ (contains initialization code)
â”œâ”€â”€ ğŸ“„ .gitignore ğŸ“
â”œâ”€â”€ ğŸ“„ LICENSE ğŸ“
â”œâ”€â”€ ğŸ“„ README.md ğŸ“
â”œâ”€â”€ ğŸ“„ requirements.txt ğŸ“
â””â”€â”€ ğŸ“„ x.ipynb ğŸ“
```

## Done âœ…

- Downloaded and structured the Cityscapes dataset (images and masks).
- Created a `Dataset` class to handle dataset intricacies for future customization if I ever introduce new datasets.
- Developed a `DataSplitter` class to create train and validation dataloaders with random sampling.
- Made the project modular with custom loss functions, custom models, and configuration files.
- Implemented logging with WandB to track metrics like loss, IOU, F1, recall, and mAP.
- Supports distributed training.

## To Do ğŸ“

- Log images through epochs, layers, and between models to gain insights into model performance on images.

## Doing ğŸ› ï¸

- Ongoing improvements and bug fixes.
- Adding additional logging and visualization features.
- Supporting mixed precision through configuration files.

## Configuration and Dependencies ğŸ› ï¸

- **Frameworks:** PyTorch, Accelerate
- **Logging:** WandB

## Example Image ğŸ–¼ï¸

Here is an example of an image similar to what the project handles in segmentation tasks:

![Segmentation Example](https://www.cityscapes-dataset.com/example_image.png)

## Usage ğŸš€

1. **Clone the repository:**

```bash
git clone <repository_url>
cd <repository_name>
```

2. **Install the dependencies:**

```bash
pip install -r requirements.txt
```

3. **Prepare the dataset:**
   Place the Cityscapes dataset images and masks in the `data/cityscapes` folder.

4. **Run training:**

```bash
python src/training/train.py --config src/config/config.yaml
```

## Contributing ğŸ¤

Feel free to open issues or submit pull requests with improvements.

## License ğŸ“„

This project is licensed under the MIT License.
